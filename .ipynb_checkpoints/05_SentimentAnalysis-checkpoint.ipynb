{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8186397e",
   "metadata": {},
   "source": [
    "# Классификация тональности текста (Text Sentiment Analysis)\n",
    "\n",
    "**Для определения тональности применим величины TF-IDF как признаки.**\n",
    "\n",
    "***Анализ тональности текста, или сентимент-анализ (от англ. sentiment, «настроение»), выявляет эмоционально окрашенные слова. Этот инструмент помогает компаниям оценивать, например, реакцию на запуск нового продукта в интернете. На разбор тысячи отзывов человек потратит несколько часов, а компьютер — пару минут.***\n",
    "\n",
    "Оценить тональность — значит отметить текст как позитивный или негативный. То есть мы решаем задачу классификации, где целевой признак равен «1» для положительного текста и «0» для отрицательного. Признаки — это слова из корпуса и их величины TF-IDF для каждого текста.\n",
    "\n",
    "### Задача\n",
    "\n",
    "- Обучите логистическую регрессию так, чтобы она определяла тональность текста.\n",
    "\n",
    "- Подсчитайте величину TF-IDF для текстов. Лемматизированные тексты твитов для обучения находятся в файле tweets_lemm_train.csv. Целевой признак вы найдёте в столбце positive.\n",
    "\n",
    "- Обученной моделью классификации определите результаты предсказания для тестовой выборки твитов, которая лежит в файле tweets_lemm_test.csv. В этой выборке целевого признака нет. Сохраните предсказания в столбце positive. Таблицу с результатом сохраните как csv-файл, но чтобы тренажёр принял файл, не указывайте расширение (например, назовите файл 'predictions')\n",
    "\n",
    "- Значение accuracy вашей модели должно быть не меньше 0.62.\n",
    "- Для предсказания ответов повторно вычислите величину TF-IDF для вектора с тестовой выборкой. Примените метод transform() к объекту TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "35ce4f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52326bd",
   "metadata": {},
   "source": [
    "### 1 Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3fe44e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>positive</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "      <td>1</td>\n",
       "      <td>хоть я и школотый но поверь у мы то же самый о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "      <td>1</td>\n",
       "      <td>да весь таки он немного похожий на он но мой м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "      <td>1</td>\n",
       "      <td>ну ты идиотка я испугаться за ты</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "      <td>1</td>\n",
       "      <td>кто то в угол сидеть и погибать от голод а мы ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\r\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>вот что значит страшилка но блин посмотреть ве...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Вроде дружили 10 лет и в один момент все разру...</td>\n",
       "      <td>0</td>\n",
       "      <td>вроде дружить год и в один момент весь разруши...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>@m_gulko \\r\\nПоэтому и поздравляю заранее, что...</td>\n",
       "      <td>0</td>\n",
       "      <td>поэтому и поздравлять заранее что не получитьс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>RT @kubudojede: черт, ну зачем они переделали ...</td>\n",
       "      <td>0</td>\n",
       "      <td>черта ну зачем они переделать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>RT @xidewojopiba: Вроде бы и любим друг друга,...</td>\n",
       "      <td>0</td>\n",
       "      <td>вроде бы и любим друг друг и быть вместе не мо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Одна из самых скучных суббот за последнее врем...</td>\n",
       "      <td>0</td>\n",
       "      <td>один из самый скучный суббота за последний вре...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  positive  \\\n",
       "0     @first_timee хоть я и школота, но поверь, у на...         1   \n",
       "1     Да, все-таки он немного похож на него. Но мой ...         1   \n",
       "2     RT @KatiaCheh: Ну ты идиотка) я испугалась за ...         1   \n",
       "3     RT @digger2912: \"Кто то в углу сидит и погибае...         1   \n",
       "4     @irina_dyshkant Вот что значит страшилка :D\\r\\...         1   \n",
       "...                                                 ...       ...   \n",
       "4995  Вроде дружили 10 лет и в один момент все разру...         0   \n",
       "4996  @m_gulko \\r\\nПоэтому и поздравляю заранее, что...         0   \n",
       "4997  RT @kubudojede: черт, ну зачем они переделали ...         0   \n",
       "4998  RT @xidewojopiba: Вроде бы и любим друг друга,...         0   \n",
       "4999  Одна из самых скучных суббот за последнее врем...         0   \n",
       "\n",
       "                                              lemm_text  \n",
       "0     хоть я и школотый но поверь у мы то же самый о...  \n",
       "1     да весь таки он немного похожий на он но мой м...  \n",
       "2                     ну ты идиотка я испугаться за ты   \n",
       "3     кто то в угол сидеть и погибать от голод а мы ...  \n",
       "4     вот что значит страшилка но блин посмотреть ве...  \n",
       "...                                                 ...  \n",
       "4995  вроде дружить год и в один момент весь разруши...  \n",
       "4996  поэтому и поздравлять заранее что не получитьс...  \n",
       "4997                     черта ну зачем они переделать   \n",
       "4998  вроде бы и любим друг друг и быть вместе не мо...  \n",
       "4999  один из самый скучный суббота за последний вре...  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/Users/yuliabezginova/PycharmProjects/00_MLForTexts/tweets_lemm_train.csv')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "de0fcd7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = train_data['positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b7aae267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @tiredfennel: если криса так интересуют дет...</td>\n",
       "      <td>если крис так интересовать ребёнок то либо они...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@xsealord по 200 руб. в месяц можно разместить...</td>\n",
       "      <td>по рубль в месяц можно разместить ссылка на те...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@haosANDlaw @Etishkindyx учитывая, что сейчас ...</td>\n",
       "      <td>учитывать что сейчас преобладать один половина...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Товарищ    :) Но я никак не могу отдельно не о...</td>\n",
       "      <td>товарищ но я никак не мочь отдельно не отметит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @BodyaNick: Квн был отличный !) Оооочень по...</td>\n",
       "      <td>квн быть отличный оооочень понравиться женский...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>жуйк, ачивки в контре — зло! мой младший брат ...</td>\n",
       "      <td>жуйк ачивка в контра зло мой младший брат втян...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>Не хочу идти на танцы :( http://t.co/5OdPjbYXOC</td>\n",
       "      <td>не хотеть идти на танец</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>На улице пусто!ни людей,ни машин,наверно холод...</td>\n",
       "      <td>на улица пусто ни человек ни машина наверно хо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>По-моему мы и ходили за водкой в три часа за э...</td>\n",
       "      <td>по мой мы и ходить за водка в три час за это ч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>Р.В сказал,что с утра будет самостоятельная,ну...</td>\n",
       "      <td>р в сказать что с утро быть самостоятельный ну...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     RT @tiredfennel: если криса так интересуют дет...   \n",
       "1     @xsealord по 200 руб. в месяц можно разместить...   \n",
       "2     @haosANDlaw @Etishkindyx учитывая, что сейчас ...   \n",
       "3     Товарищ    :) Но я никак не могу отдельно не о...   \n",
       "4     RT @BodyaNick: Квн был отличный !) Оооочень по...   \n",
       "...                                                 ...   \n",
       "2995  жуйк, ачивки в контре — зло! мой младший брат ...   \n",
       "2996    Не хочу идти на танцы :( http://t.co/5OdPjbYXOC   \n",
       "2997  На улице пусто!ни людей,ни машин,наверно холод...   \n",
       "2998  По-моему мы и ходили за водкой в три часа за э...   \n",
       "2999  Р.В сказал,что с утра будет самостоятельная,ну...   \n",
       "\n",
       "                                              lemm_text  \n",
       "0     если крис так интересовать ребёнок то либо они...  \n",
       "1     по рубль в месяц можно разместить ссылка на те...  \n",
       "2     учитывать что сейчас преобладать один половина...  \n",
       "3     товарищ но я никак не мочь отдельно не отметит...  \n",
       "4     квн быть отличный оооочень понравиться женский...  \n",
       "...                                                 ...  \n",
       "2995  жуйк ачивка в контра зло мой младший брат втян...  \n",
       "2996                           не хотеть идти на танец   \n",
       "2997  на улица пусто ни человек ни машина наверно хо...  \n",
       "2998  по мой мы и ходить за водка в три час за это ч...  \n",
       "2999  р в сказать что с утро быть самостоятельный ну...  \n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('/Users/yuliabezginova/PycharmProjects/00_MLForTexts/tweets_lemm_test.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7db070",
   "metadata": {},
   "source": [
    "### 2 Масштабирование данных с помощью tf-idf\n",
    "\n",
    "Следующий подход вместо исключения несущественных признаков пытается масштабировать признаки в зависимости от степени их информативности. Одним из наиболее распространенных способов такого масштабирования является метод частота термина-обратная частота документа (term frequency-inverse document frequency, tf-idf). \n",
    "\n",
    "Идея этого метода заключается в том, чтобы присвоить большой вес термину, который часто встречается в конкретном документе, но при этом редко встречается в остальных документах корпуса. Если слово часто появляется в конкретном документе, но при этом редко встречается в остальных документах, оно, вероятно, будет описывать содержимое этого документа лучше.\n",
    "\n",
    "#### В библиотеке scikit-learn метод tf-idf реализован в двух классах: TfidfTransformer, который принимает на вход разреженную матрицу, полученную с помощью CountVectorizer, и преобразует ее, и TfidfVectorizer, который принимает на вход текстовые данные и выполняет как выделение признаков «мешок слов», так и преобразование tf-idf.\n",
    "\n",
    "Поскольку tf-idf фактически использует статистические свойства\n",
    "обучающих данных, мы воспользуемся конвейером (о котором\n",
    "рассказывалось в главе 6), чтобы убедиться в достоверности результатов\n",
    "нашего решетчатого поиска. Для этого пишем следующий программный\n",
    "код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c5fd6ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yuliabezginova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9178cc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим счётчик, указав в нём стоп-слова\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5681bd",
   "metadata": {},
   "source": [
    "### 3 Деление данных на подвыборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "161f4a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 132 ms, sys: 5.82 ms, total: 138 ms\n",
      "Wall time: 141 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Чтобы посчитать TF-IDF для корпуса текстов, вызовем функцию fit_transform():\n",
    "tf_idf_train = count_tf_idf.fit_transform(train_data['lemm_text'])\n",
    "tf_idf_test = count_tf_idf.transform(test_data['lemm_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "de991888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (5000, 9737)\n",
      "Размер матрицы: (3000, 9737)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер матрицы:\", tf_idf_train.shape)\n",
    "print(\"Размер матрицы:\", tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d638a365",
   "metadata": {},
   "source": [
    "### 4 Обучение логистической регрессии (подбор параметров решетчатым поиском)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "81519603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [   nan 0.6262    nan 0.6296    nan 0.6362    nan 0.6358    nan 0.6182\n",
      "    nan 0.6018]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(random_state=5), n_jobs=-1,\n",
       "             param_grid=[{&#x27;C&#x27;: [0.01, 0.1, 1, 2, 10, 100],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]}],\n",
       "             verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(random_state=5), n_jobs=-1,\n",
       "             param_grid=[{&#x27;C&#x27;: [0.01, 0.1, 1, 2, 10, 100],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]}],\n",
       "             verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(random_state=5), n_jobs=-1,\n",
       "             param_grid=[{'C': [0.01, 0.1, 1, 2, 10, 100],\n",
       "                          'penalty': ['l1', 'l2']}],\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=5)\n",
    "\n",
    "# param_grid = [{\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}]\n",
    "param_grid = [\n",
    "    {'C': [0.01, 0.1, 1, 2, 10, 100], 'penalty': ['l1', 'l2']}\n",
    "]\n",
    "# =109.85411419875572, class_weight=None, dual=False,\n",
    "#           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "#           multi_class='warn', n_jobs=None, penalty='l1', random_state=None,\n",
    "#           solver='warn', tol=0.0001, verbose=0, warm_start=False\n",
    "\n",
    "logreg_grid = GridSearchCV(logreg, param_grid, cv=5, verbose=True, n_jobs=-1)\n",
    "\n",
    "logreg_grid.fit(tf_idf_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e943503",
   "metadata": {},
   "source": [
    "### 5 Предсказания на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6632c41b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшее значение перекр проверки: 0.64\n"
     ]
    }
   ],
   "source": [
    "predictions = logreg_grid.predict(tf_idf_test)\n",
    "print(\"Наилучшее значение перекр проверки: {:.2f}\".format(logreg_grid.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95e9ef0",
   "metadata": {},
   "source": [
    "### 6 Запишем файл с предсказаниями на тестовой выборке для загрузки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d94c9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'positive':predictions})\n",
    "submission.to_csv('predictions', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c36ecdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.read_csv(\"/Users/yuliabezginova/PycharmProjects/00_MLForTexts/predictions\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8617b4c",
   "metadata": {},
   "source": [
    "***Thank you for going through this project. Your comments are more then welcome to ybezginova2021@gmail.com***\n",
    "\n",
    "***Best wishes,***\n",
    "\n",
    "***Yulia***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
